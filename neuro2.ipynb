{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c508ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 1. DEFINE THE STYLE\n",
    "# -----------------------------------------------------------------\n",
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 2. DEFINE dlc COLORS\n",
    "# -----------------------------------------------------------------\n",
    "dlc = {\n",
    "    \"dlblue\": \"#0096ff\",\n",
    "    \"dlorange\": \"#FF9300\",\n",
    "    \"dldarkred\": \"#C00000\",\n",
    "    \"dlmagenta\": \"#FF40FF\",\n",
    "    \"dlpurple\": \"#7030A0\",\n",
    "    \"dldarkblue\": \"#0D5BDC\"\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3. DEFINE COFFEE DATA FUNCTIONS\n",
    "# -----------------------------------------------------------------\n",
    "def load_coffee_data():\n",
    "    \"\"\"Creates coffee roasting data for classification.\"\"\"\n",
    "    X = np.array([[200, 13.9],  # Good roast\n",
    "                  [214, 17.5],\n",
    "                  [220, 15.8],\n",
    "                  [205, 15.4],\n",
    "                  [188, 16.6],  # Bad roast\n",
    "                  [175, 19.2],\n",
    "                  [185, 17.9],\n",
    "                  [168, 18.1]])\n",
    "    y = np.array([1, 1, 1, 1, 0, 0, 0, 0])\n",
    "    return X, y\n",
    "\n",
    "def plt_roast(X, y):\n",
    "    \"\"\"Plot coffee roasting data with good/bad roast classification\"\"\"\n",
    "    Y = y.reshape(-1,)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    ax.scatter(X[Y==0, 0], X[Y==0, 1], s=100, marker='x', c='red', label=\"Bad Roast\")\n",
    "    ax.scatter(X[Y==1, 0], X[Y==1, 1], s=100, marker='o', c='blue', label=\"Good Roast\")\n",
    "    ax.set_xlabel(\"Temperature \\N{DEGREE SIGN}C\")\n",
    "    ax.set_ylabel(\"Duration (min)\")\n",
    "    ax.set_title(\"Coffee Roasting Data\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plt_prob(model, X, y):\n",
    "    \"\"\"Plot probability predictions\"\"\"\n",
    "    yhat = model.predict(X)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    sort_indices = np.argsort(X[:, 0])\n",
    "    X_sorted = X[sort_indices]\n",
    "    yhat_sorted = yhat[sort_indices]\n",
    "    ax.plot(X_sorted[:, 0], yhat_sorted, c=dlc[\"dlblue\"], linewidth=2, label=\"Prediction\")\n",
    "    ax.scatter(X[y==0, 0], y[y==0], s=100, marker='x', c='red', label=\"Bad Roast\")\n",
    "    ax.scatter(X[y==1, 0], y[y==1], s=100, marker='o', c='blue', label=\"Good Roast\")\n",
    "    ax.set_xlabel(\"Temperature \\N{DEGREE SIGN}C\")\n",
    "    ax.set_ylabel(\"Probability of Good Roast\")\n",
    "    ax.set_title(\"Model Predictions\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plt_layer(X, Y, predicted, layer_name):\n",
    "    \"\"\"Plot layer activations\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    h = 0.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = predicted(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    ax.scatter(X[Y==0, 0], X[Y==0, 1], s=100, marker='x', c='red', label=\"Bad Roast\")\n",
    "    ax.scatter(X[Y==1, 0], X[Y==1, 1], s=100, marker='o', c='blue', label=\"Good Roast\")\n",
    "    ax.set_xlabel(\"Temperature \\N{DEGREE SIGN}C\")\n",
    "    ax.set_ylabel(\"Duration (min)\")\n",
    "    ax.set_title(f\"Layer: {layer_name}\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plt_network(X, y, model):\n",
    "    \"\"\"Visualize neural network predictions\"\"\"\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    h = 0.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = (Z > 0.5).astype(int).reshape(xx.shape)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n",
    "    ax.scatter(X[y==0, 0], X[y==0, 1], s=100, marker='x', c='red', label=\"Bad Roast\")\n",
    "    ax.scatter(X[y==1, 0], X[y==1, 1], s=100, marker='o', c='blue', label=\"Good Roast\")\n",
    "    ax.set_xlabel(\"Temperature \\N{DEGREE SIGN}C\")\n",
    "    ax.set_ylabel(\"Duration (min)\")\n",
    "    ax.set_title(\"Neural Network Decision Boundary\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plt_output_unit(weights, bias):\n",
    "    \"\"\"Visualize single neuron parameters\"\"\"\n",
    "    print(f\"Weights: {weights.flatten()}\")\n",
    "    print(f\"Bias: {bias[0]}\")\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    x_pos = np.arange(len(weights))\n",
    "    ax.bar(x_pos, weights.flatten(), color=dlc[\"dlblue\"])\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.set_xlabel(\"Input Feature\")\n",
    "    ax.set_ylabel(\"Weight Value\")\n",
    "    ax.set_title(f\"Neuron Weights (Bias = {bias[0]:.2f})\")\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(['Neuron 1', 'Neuron 2', 'Neuron 3'])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 4. MAIN EXECUTION CODE\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# Load and visualize data\n",
    "X, y = load_coffee_data()\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "print(f\"X samples:\\n{X}\")\n",
    "print(f\"y labels: {y}\")\n",
    "plt_roast(X, y)\n",
    "\n",
    "# Normalize data\n",
    "print(f\"\\nTemperature Max, Min pre normalization: {np.max(X[:,0]):0.2f}, {np.min(X[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min pre normalization: {np.max(X[:,1]):0.2f}, {np.min(X[:,1]):0.2f}\")\n",
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)  # learns mean, variance\n",
    "Xn = norm_l(X)\n",
    "print(f\"\\nTemperature Max, Min post normalization: {np.max(Xn[:,0]):0.2f}, {np.min(Xn[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min post normalization: {np.max(Xn[:,1]):0.2f}, {np.min(Xn[:,1]):0.2f}\")\n",
    "\n",
    "# Create duplicated data (for training)\n",
    "Xt = np.tile(Xn, (1000, 1))  # 1000 copies vertically\n",
    "Yt = np.tile(y.reshape(-1, 1), (1000, 1))   \n",
    "print(f\"\\nXt shape: {Xt.shape}, Yt shape: {Yt.shape}\")\n",
    "\n",
    "# Build neural network\n",
    "tf.random.set_seed(1234)  # for consistent results\n",
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(2,)),\n",
    "    Dense(3, activation='sigmoid', name='layer1'),\n",
    "    Dense(1, activation='sigmoid', name='layer2')\n",
    "])\n",
    "\n",
    "# Calculate parameters\n",
    "L1_num_params = 2 * 3 + 3   # W1 parameters + b1 parameters\n",
    "L2_num_params = 3 * 1 + 1   # W2 parameters + b2 parameters\n",
    "print(f\"\\nL1 params = {L1_num_params}, L2 params = {L2_num_params}\")\n",
    "print(f\"Total parameters: {L1_num_params + L2_num_params}\")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\n--- TRAINING THE MODEL ---\")\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    ")\n",
    "model.fit(Xt, Yt, epochs=10)\n",
    "\n",
    "# Extract and display weights\n",
    "print(\"\\n--- MODEL WEIGHTS ---\")\n",
    "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
    "print(f\"W1{W1.shape}:\\n\", W1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"\\nW2{W2.shape}:\\n\", W2, f\"\\nb2{b2.shape}:\", b2)\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\n--- MAKING PREDICTIONS ---\")\n",
    "X_test = np.array([[200, 13.9],   # Should predict 1 (good)\n",
    "                   [175, 19.2]])  # Should predict 0 (bad)\n",
    "X_test_norm = norm_l(X_test)\n",
    "predictions = model.predict(X_test_norm)\n",
    "print(f\"Raw predictions (probabilities):\\n{predictions}\")\n",
    "\n",
    "# Convert to binary decisions\n",
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"Binary decisions:\\n{yhat}\")\n",
    "\n",
    "# Visualizations\n",
    "print(\"\\n--- VISUALIZATIONS ---\")\n",
    "plt_prob(model, Xn, y)\n",
    "\n",
    "# Set pre-trained weights (for comparison/consistency)\n",
    "print(\"\\n--- SETTING PRE-TRAINED WEIGHTS ---\")\n",
    "W1_trained = np.array([[-8.94,  0.29, 12.89],\n",
    "                       [-0.17, -7.34, 10.79]])\n",
    "b1_trained = np.array([-9.87, -9.28,  1.01])\n",
    "W2_trained = np.array([[-31.38],\n",
    "                       [-27.86],\n",
    "                       [-32.79]])\n",
    "b2_trained = np.array([15.54])\n",
    "\n",
    "model.get_layer(\"layer1\").set_weights([W1_trained, b1_trained])\n",
    "model.get_layer(\"layer2\").set_weights([W2_trained, b2_trained])\n",
    "\n",
    "# Show layer visualizations\n",
    "print(\"\\n--- LAYER VISUALIZATIONS ---\")\n",
    "plt_layer(X, y.reshape(-1,), lambda x: model.get_layer(\"layer1\")(norm_l(x)), \"layer1\")\n",
    "plt_output_unit(W2_trained, b2_trained)\n",
    "\n",
    "# Show final network decision boundary\n",
    "print(\"\\n--- FINAL DECISION BOUNDARY ---\")\n",
    "netf = lambda x: model.predict(norm_l(x))\n",
    "plt_network(X, y, netf)\n",
    "\n",
    "print(\"\\nâœ… Program completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
