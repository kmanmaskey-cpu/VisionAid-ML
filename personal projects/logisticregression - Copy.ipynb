{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fcc7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [-0.73759088 -0.63005019 -1.0882258  -1.11089174 -0.67734941]\n",
      "Bias: -3.761876740462188\n",
      "Prediction: malignant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8148\\644239308.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_regression(x_train, y_train, learning_rate, num_of_iterations):\n",
    "    m = len(y_train)\n",
    "    weights = np.zeros(x_train.shape[1])\n",
    "    bias = 0\n",
    "\n",
    "    for i in range(num_of_iterations):\n",
    "        y_pred = sigmoid(np.dot(x_train, weights) + bias)\n",
    "        \n",
    "        # FIX 1: Use different variable for gradient\n",
    "        gradient = (1/m) * (np.dot(x_train.T, (y_pred - y_train)))\n",
    "        bias_gradient = (1/m) * np.sum((y_pred - y_train))  # Changed variable name\n",
    "        \n",
    "        weights -= learning_rate * gradient\n",
    "        bias -= learning_rate * bias_gradient  # Now uses bias_gradient\n",
    "    \n",
    "    return weights, bias\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "def normalize_train(X):\n",
    "    min_vals = np.min(X, axis=0)\n",
    "    max_vals = np.max(X, axis=0)\n",
    "    X_norm = (X - min_vals) / (max_vals - min_vals + 1e-8)\n",
    "    return X_norm, min_vals, max_vals\n",
    "\n",
    "x_train_norm, train_min, train_max = normalize_train(\n",
    "    df[['concave points_mean', 'concavity_mean', 'perimeter_mean', 'radius_mean', 'area_mean']].values\n",
    ")\n",
    "\n",
    "\n",
    "y_train = df['diagnosis'] \n",
    "\n",
    "weights, bias = logistic_regression(x_train_norm, y_train, 0.1, 1000) \n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)\n",
    "\n",
    "# Get input (use different variable names)\n",
    "inp1 = float(input(\"Enter concave points_mean: \"))\n",
    "inp2 = float(input(\"Enter concavity_mean: \"))\n",
    "inp3 = float(input(\"Enter perimeter_mean: \"))\n",
    "inp4 = float(input(\"Enter radius_mean: \"))\n",
    "inp5 = float(input(\"Enter area_mean: \"))\n",
    "\n",
    "new_input = np.array([[inp1, inp2, inp3, inp4, inp5]]) \n",
    "new_input_norm = (new_input - train_min) / (train_max - train_min + 1e-8)\n",
    "\n",
    "z = np.dot(new_input_norm, weights) + bias\n",
    "probability = sigmoid(z)[0] \n",
    "\n",
    "if probability < 0.5:\n",
    "    print(\"Prediction: malignant\")\n",
    "else:\n",
    "    print(\"Prediction: benign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d011c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
