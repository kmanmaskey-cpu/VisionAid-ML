{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0beaefd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bb7ad076bb498aaf80efa78d198167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For interactive plots in Jupyter\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Output, interactive\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Close any existing plots\n",
    "plt.close(\"all\")\n",
    "\n",
    "# Create output widget\n",
    "output = Output()\n",
    "display(output)\n",
    "\n",
    "# Custom overfit_example function\n",
    "def overfit_example(regularized=True):\n",
    "    \"\"\"\n",
    "    Demonstrates overfitting vs regularization\n",
    "    \"\"\"\n",
    "    # Generate synthetic data\n",
    "    np.random.seed(42)\n",
    "    X_train = np.random.rand(20, 1) * 10\n",
    "    y_train = np.sin(X_train.ravel()) + np.random.randn(20) * 0.3\n",
    "    \n",
    "    if regularized:\n",
    "        # Simple linear model (underfit/regularized)\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        degree = 1\n",
    "    else:\n",
    "        # Complex polynomial (overfit)\n",
    "        degree = 15\n",
    "        poly = PolynomialFeatures(degree=degree)\n",
    "        X_poly = poly.fit_transform(X_train)\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_poly, y_train)\n",
    "    \n",
    "    # Generate test data for smooth curve\n",
    "    X_test = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "    \n",
    "    if regularized:\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        X_test_poly = poly.transform(X_test)\n",
    "        y_pred = model.predict(X_test_poly)\n",
    "    \n",
    "    # Plot\n",
    "    with output:\n",
    "        output.clear_output(wait=True)  # Clear previous output\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Plot training data\n",
    "        plt.scatter(X_train, y_train, color='blue', s=50, \n",
    "                   label='Training Data', alpha=0.7)\n",
    "        \n",
    "        # Plot true function (for comparison)\n",
    "        y_true = np.sin(X_test.ravel())\n",
    "        plt.plot(X_test, y_true, 'g--', linewidth=2, \n",
    "                label='True Function: sin(x)', alpha=0.7)\n",
    "        \n",
    "        # Plot model prediction\n",
    "        color = 'orange' if regularized else 'red'\n",
    "        label = 'Regularized (degree=1)' if regularized else f'Overfit (degree={degree})'\n",
    "        plt.plot(X_test, y_pred, color=color, linewidth=3, label=label)\n",
    "        \n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('y')\n",
    "        plt.title('Overfitting Demonstration')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.ylim(-1.5, 1.5)\n",
    "        plt.show()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Run the example\n",
    "ofit = overfit_example(False)  # Show overfit example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
